{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q2_1.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvy0nLncR0DtCW6ks7zLqZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"d58dapmvDq9l"},"source":["# A B C"]},{"cell_type":"code","metadata":{"id":"NV1hKQvOPgpx"},"source":["import numpy as np\n","import keras\n","from keras import backend as k\n","from keras.layers.core import Dense\n","from keras.optimizers import Adam\n","from keras.metrics import categorical_crossentropy\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Model\n","from keras.applications import imagenet_utils\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from google.colab import drive\n","import tensorflow as tf\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1V6JQJ1TQ394"},"source":["nas_net = tf.keras.applications.nasnet.NASNetMobile()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PRb6PwNARNWm"},"source":["def prepare_img(file):\n","  img_path = \"/content/drive/My Drive/Neural network/HW3/\"\n","  img = image.load_img(img_path + file, target_size = (224, 224))\n","  img_array = image.img_to_array(img)\n","  img_array_expand_dims = np.expand_dims(img_array, axis = 0)\n","  tf.keras.applications.nasnet.preprocess_input(img_array_expand_dims)\n","  return img_array_expand_dims"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJouyTjlSInn"},"source":["preprocessed_image = prepare_img('rider-10.jpg')\n","print(preprocessed_image.shape)\n","predictions = nas_net.predict(preprocessed_image)\n","results = imagenet_utils.decode_predictions(predictions)\n","results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6e6om9jCXwD1"},"source":["# D"]},{"cell_type":"code","metadata":{"id":"80dO7L1tXuKO"},"source":["if results[0][0][2]> 0.5:\n","  print(\"this picture is of type:\",results[0][0][1])\n","else:\n","  print(\"this picture is unknown\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JSiEoVJ-_ARI"},"source":["# E"]},{"cell_type":"code","metadata":{"id":"FhqChlhHiGlO"},"source":["import os\n","import time\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout,Activation,Flatten\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.utils import np_utils\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.optimizers import SGD\n","import keras\n","import keras.utils\n","from keras import utils as np_utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbWbA6nLiGlO"},"source":["PATH =  \"/content/drive/My Drive/Neural network/HW3/data/\"\n","data_path = PATH + '/DATA1'\n","data_dir_list = os.listdir(data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkqdAUSTiGlO"},"source":["img_data_list=[]\n","\n","for dataset in data_dir_list:\n","\timg_list=os.listdir(data_path+'/'+ dataset)\n","\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n","\tfor img in img_list:\n","\t\timg_path = data_path + '/'+ dataset + '/'+ img \n","\t\timg = image.load_img(img_path, target_size=(224, 224))\n","\t\tx = image.img_to_array(img)\n","\t\tx = np.expand_dims(x, axis=0)\n","\t\tx = tf.keras.applications.nasnet.preprocess_input(x)\n","\t\timg_data_list.append(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilr0pd85iGlO"},"source":["img_data = np.array(img_data_list)\n","print (img_data.shape)\n","img_data=np.rollaxis(img_data,1,0)\n","print (img_data.shape)\n","img_data=img_data[0]\n","print (img_data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2fZxkZeiGlO"},"source":["# Define the number of classes\n","num_classes = 2\n","num_of_samples = img_data.shape[0]\n","labels = np.ones((num_of_samples,),dtype='int64')\n","\n","labels[0:202]=0\n","labels[202:404]=1\n","\n","#names = ['cats','dogs']\n","names = ['horses','humans']\n","# convert class labels to on-hot encoding\n","Y = np_utils.to_categorical(labels, num_classes)\n","\n","#Shuffle the dataset\n","x,y = shuffle(img_data,Y, random_state=2)\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsuD7x4jiGlO"},"source":["model = tf.keras.applications.nasnet.NASNetMobile(weights='imagenet',include_top=False)\n","last_layer = model.output\n","# add a global spatial average pooling layer\n","x = GlobalAveragePooling2D()(last_layer)\n","# add fully-connected & dropout layers\n","x = Dense(512, activation='relu',name='fc-1')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(256, activation='relu',name='fc-2')(x)\n","x = Dropout(0.5)(x)\n","# a softmax layer for 2 classes\n","out = Dense(num_classes, activation='softmax',name='output_layer')(x)\n","\n","# this is the model we will train\n","custom_NAS_net_mode = Model(inputs=model.input, outputs=out)\n","\n","custom_NAS_net_mode.summary()\n","\n","for layer in custom_NAS_net_mode.layers[:-6]:\n","\tlayer.trainable = False\n","\n","custom_NAS_net_mode.layers[-1].trainable\n","\n","custom_NAS_net_mode.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","t=time.time()\n","#trained_model = custom_NAS_net_mode.fit(X_train, y_train,batch_size=64,epochs=20,validation_split=0.2)\n","trained_model = custom_NAS_net_mode.fit(X_train, y_train, batch_size=64, epochs=20, verbose=1, validation_data=(X_test, y_test))\n","print('Training time: %s' % (t - time.time()))\n","(loss, accuracy) = custom_NAS_net_mode.evaluate(X_test, y_test, batch_size=10, verbose=1)\n","\n","print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlTKN_dKiGlO"},"source":["import matplotlib.pyplot as plt\n","def plot_details(trained_model):\n","    history=trained_model.history\n","    acc=history['accuracy']\n","    val_acc=history['val_accuracy']\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('accuracy')\n","    plt.plot(acc)\n","    plt.plot(val_acc)\n","    plt.legend(['acc','val_acc'])\n","    plt.title('accuracy')\n","    los = history['loss']\n","    val_los = history['val_loss']\n","    los = history['loss']\n","    val_los = history['val_loss']\n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('loss')\n","    plt.plot(los)\n","    plt.plot(val_los)\n","    plt.legend(['loss','val_loss'])\n","    plt.title('loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5gdkUK3iGlO"},"source":["plot_details(trained_model)"],"execution_count":null,"outputs":[]}]}