{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2_HW4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-QD6x-ONhCN"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "#basis\r\n",
        "e1 = [1,-1,1,-1,1,-1]\r\n",
        "e2 = [-1,1,-1,1,-1,1]\r\n",
        "e3 = [1,1,1,1,1,1]\r\n",
        "e4 = [1,1,-1,-1,1,-1]\r\n",
        "\r\n",
        "# vectors\r\n",
        "v1 = np.array([[1,-1,1,1,1,1]])\r\n",
        "v2 = np.array([[-1,-1,1,1,1,1]])\r\n",
        "v3 = np.array([[1,-1,1,-1,-1,1]])\r\n",
        "v4 = np.array([[1,1,1,-1,-1,-1]])\r\n",
        "v5 = np.array([[-1,-1,-1,-1,1,-1]])\r\n",
        "v6 = np.array([[-1,-1,1,1,-1,-1]])\r\n",
        "v7 = np.array([[1,1,1,1,1,-1]])\r\n",
        "v8 = np.array([[1,1,-1,-1,1,-1]])\r\n",
        "vectors = np.array([v1,v2,v3,v4,v5,v6,v7,v8])\r\n",
        "\r\n",
        "# weight and bias\r\n",
        "W = np.array([e1,e2,e3,e4]).T/2\r\n",
        "b = np.array([[len(e1)/2]*4])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFqRDNknfHzh",
        "outputId": "4fe06514-0c70-46ae-8294-f9ad9921bfbc"
      },
      "source": [
        "print(f\"W = \\n {W} \\n\\nbias = \\n {b}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W = \n",
            " [[ 0.5 -0.5  0.5  0.5]\n",
            " [-0.5  0.5  0.5  0.5]\n",
            " [ 0.5 -0.5  0.5 -0.5]\n",
            " [-0.5  0.5  0.5 -0.5]\n",
            " [ 0.5 -0.5  0.5  0.5]\n",
            " [-0.5  0.5  0.5 -0.5]] \n",
            "\n",
            "bias = \n",
            " [[3. 3. 3. 3.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Ed4zdRkILg"
      },
      "source": [
        "from copy import deepcopy\r\n",
        "\r\n",
        "def HammingNet(vect, weight, bias):\r\n",
        "  return vect.dot(weight) + bias\r\n",
        "\r\n",
        "def f_x(x):\r\n",
        "  return np.where(x<0, 0, x)\r\n",
        "\r\n",
        "def MaxNet(x, epsilon):\r\n",
        "  m = len(x)\r\n",
        "  w = np.ones((m,m)) * -epsilon\r\n",
        "  np.fill_diagonal(w, 1)\r\n",
        "\r\n",
        "  return f_x(w.dot(x))\r\n",
        "\r\n",
        "def MaxNet_iteration(x, epsilon):\r\n",
        "  x_old = deepcopy(x.flatten())\r\n",
        "  indx = 0\r\n",
        "  for i in range(1000):\r\n",
        "    x_new = MaxNet(x_old, epsilon)\r\n",
        "    x_old = x_new\r\n",
        "\r\n",
        "    if np.count_nonzero(x_new) == 1:\r\n",
        "      indx = int(np.flatnonzero(x_new))\r\n",
        "      break\r\n",
        "\r\n",
        "  return indx\r\n",
        "\r\n",
        "def HammingNN(vect, weight, bias, epsilon):\r\n",
        "  y_in = HammingNet(vect, weight, bias)\r\n",
        "  ind = MaxNet_iteration(y_in, epsilon)\r\n",
        "  return ind"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WmVZUjHZ-ln",
        "outputId": "4e3dec3f-cef4-445c-f1b0-846f911d361b"
      },
      "source": [
        "HammingNet(v1, W, b)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4., 2., 5., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04zmgNGHaF4K",
        "outputId": "a139c520-dfee-48d0-bd44-30db6de68ee6"
      },
      "source": [
        "MaxNet_iteration(HammingNet(v1, W, b), 0.1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfAI6ttRecCg",
        "outputId": "5ecd73b3-1e5e-4f10-fa4c-77bf3a91c6a1"
      },
      "source": [
        "HammingNN(v1, W, b, 0.1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEBBJZkid_YZ",
        "outputId": "94d080af-51de-4952-bdb0-925e55788e4d"
      },
      "source": [
        "for cnt, vec in enumerate(vectors):\r\n",
        "  print(f'v{cnt+1} is close to basis e{HammingNN(vec, W, b, 0.1)+1}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v1 is close to basis e3\n",
            "v2 is close to basis e3\n",
            "v3 is close to basis e1\n",
            "v4 is close to basis e1\n",
            "v5 is close to basis e1\n",
            "v6 is close to basis e2\n",
            "v7 is close to basis e3\n",
            "v8 is close to basis e4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}